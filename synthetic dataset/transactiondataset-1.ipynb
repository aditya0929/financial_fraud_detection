{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-23T09:07:06.430782Z","iopub.execute_input":"2023-12-23T09:07:06.431199Z","iopub.status.idle":"2023-12-23T09:07:06.438357Z","shell.execute_reply.started":"2023-12-23T09:07:06.431165Z","shell.execute_reply":"2023-12-23T09:07:06.436958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install faker ","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:07:09.780410Z","iopub.execute_input":"2023-12-23T09:07:09.780806Z","iopub.status.idle":"2023-12-23T09:07:25.182826Z","shell.execute_reply.started":"2023-12-23T09:07:09.780772Z","shell.execute_reply":"2023-12-23T09:07:25.181408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom datetime import datetime, timedelta\nfrom faker import Faker\n\n# Set seeds for reproducibility\nnp.random.seed(42)\nrandom.seed(42)\nFaker.seed(42)\n\n# Initialize Faker\nfake = Faker()\n\n# Create an empty DataFrame to store the data\ncolumns = [\"user_id\", \"name\", \"addresses\", \"email_address\", \"age\", \"kyc_status\", \"days_since_kyc_incomplete\",\n           \"transaction_id\", \"transaction_amount\", \"transaction_date\", \"home_branch\", \"transaction_location\",\n           \"transaction_method\", \"transaction_category\", \"transaction_merchant\", \"transaction_time\",\n           \"average_expenditure\", \"comparison_with_avg_expenditure\", \"transaction_count_7_days\", \"fraud_indicator\",\n           \"suspicion_indicator\"]\n\ndata = []\n\n# Generate the dataset\nfor user_id in range(1, 20001):\n    name = f\"name {user_id}\"\n    addresses = fake.address()\n    email_address = fake.email()\n    age = random.randint(18, 75)\n    kyc_status = \"incomplete\" if random.random() < 0.1 else \"complete\"\n    days_since_kyc_incomplete = np.random.randint(1, 365) if kyc_status == \"incomplete\" else 0\n    transaction_id = f\"transaction_id{random.randint(10000, 99999)}\"\n    transaction_amount = np.random.uniform(1000, 150000)\n    transaction_date = fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d')\n    home_branch = fake.city()\n\n    num_random_cities = 2\n    transaction_location_choices = [home_branch] + [fake.city() for _ in range(num_random_cities)] + [\"unknown\"]\n    transaction_location_probabilities = [0.8] + [0.1 / num_random_cities] * num_random_cities + [0.1]\n    transaction_location = np.random.choice(transaction_location_choices, p=transaction_location_probabilities)\n\n    if transaction_location != home_branch and transaction_location not in transaction_location_choices[1:]:\n        transaction_location = \"unknown\"\n\n    transaction_method = np.random.choice([\"cash\", \"card\", \"online\", \"upi\"])\n    transaction_category = np.random.choice([\"travel\", \"food\", \"loan\", \"recreation\"])\n    transaction_merchant = fake.company()\n\n    transaction_time = fake.time_object().strftime('%H:%M:%S')\n\n    average_expenditure = np.random.uniform(1000, 80000)\n    comparison_with_avg_expenditure = transaction_amount - average_expenditure\n\n    transaction_count_7_days = int(np.random.normal(loc=10, scale=5))\n    transaction_count_7_days = max(1, min(30, transaction_count_7_days))\n\n    # Adjusted conditions for fraud to create a better balance\n    fraud_conditions = [\n        comparison_with_avg_expenditure > 30000,\n        transaction_amount > 110000,\n        0 <= int(transaction_time.split(':')[0]) < 5,\n        transaction_location not in [home_branch, \"unknown\"],\n        transaction_count_7_days > 18\n    ]\n\n    # Mark transaction as fraudulent if at least two conditions are met\n    fraud_indicator = 1 if sum(fraud_conditions) >= 2 else 0\n\n    # New feature: Suspicion Indicator\n    suspicion_indicator = 1 if any(fraud_conditions) else 0\n\n    data.append([user_id, name, addresses, email_address, age, kyc_status, days_since_kyc_incomplete,\n                 transaction_id, transaction_amount, transaction_date, home_branch, transaction_location,\n                 transaction_method, transaction_category, transaction_merchant, transaction_time,\n                 average_expenditure, comparison_with_avg_expenditure, transaction_count_7_days, fraud_indicator,\n                 suspicion_indicator])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T10:45:44.876187Z","iopub.execute_input":"2023-12-23T10:45:44.876654Z","iopub.status.idle":"2023-12-23T10:46:10.749356Z","shell.execute_reply.started":"2023-12-23T10:45:44.876621Z","shell.execute_reply":"2023-12-23T10:46:10.748445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define 50 pairs of users with the same addresses and email IDs\naddress_email_pairs = [(3, 15), (37, 3839)] + [(i, i + 1) for i in range(8000, 8200, 2)]\n\n# Ensure specific pairs of user IDs have the same addresses and email IDs\nfor user_id1, user_id2 in address_email_pairs:\n    email_pair = fake.email()\n    address_pair = fake.address()\n    df.loc[df['user_id'].isin([user_id1, user_id2]), ['email_address', 'addresses']] = email_pair, address_pair\n\n# Define 48 pairs of users with the same transaction merchants\nmerchant_pairs = [(5, 17), (39, 3941)] + [(i, i + 1) for i in range(4000, 4200, 2)]\n\n# Ensure specific pairs of user IDs have the same transaction merchants\nfor user_id1, user_id2 in merchant_pairs:\n    merchant_pair = fake.company()\n    df.loc[df['user_id'].isin([user_id1, user_id2]), 'transaction_merchant'] = merchant_pair\n\n# Create DataFrame\ndf = pd.DataFrame(data, columns=columns)\n\n# Display the DataFrame with formatted names\nfor index, row in df.head().iterrows():\n    print(f\"User ID {row['user_id']} is having {row['name']}\")\n\n# Save DataFrame to a CSV file\ndf.to_csv('TransactionDataset1.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T10:47:09.748170Z","iopub.execute_input":"2023-12-23T10:47:09.749163Z","iopub.status.idle":"2023-12-23T10:47:10.584477Z","shell.execute_reply.started":"2023-12-23T10:47:09.749121Z","shell.execute_reply":"2023-12-23T10:47:10.583437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}