{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7282058,"sourceType":"datasetVersion","datasetId":4222368}],"dockerImageVersionId":30628,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-29T07:20:45.249391Z","iopub.execute_input":"2023-12-29T07:20:45.249686Z","iopub.status.idle":"2023-12-29T07:20:45.597654Z","shell.execute_reply.started":"2023-12-29T07:20:45.249659Z","shell.execute_reply":"2023-12-29T07:20:45.596910Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/credit-debit dataset.csv\n/kaggle/input/dataset/TransactionDataset1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error, r2_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# Load the first dataset\ndata = pd.read_csv('/kaggle/input/dataset/TransactionDataset1.csv')\n\n# Drop unnecessary columns\ndrop_columns = ['user_id', 'name', 'addresses', 'email_address', 'transaction_id', 'transaction_date']\ndata = data.drop(drop_columns, axis=1)\n\n# Convert categorical variables to numerical using Label Encoding\nlabel_encoder = LabelEncoder()\nfor column in data.select_dtypes(include=['object']).columns:\n    data[column] = label_encoder.fit_transform(data[column])\n\n# Split the data into features (X) and target variable (y)\nX = data.drop('fraud_indicator', axis=1)\ny = data['fraud_indicator']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Choose a model (Random Forest)\nmodel = RandomForestClassifier(n_estimators=1000, random_state=42, verbose=1)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrsquared = r2_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\n# Display results for the first model\nprint(f'First Model Results:')\nprint(f'Accuracy: {accuracy:.2f}')\nprint(f'Mean Squared Error: {mse:.2f}')\nprint(f'R-squared: {rsquared:.2f}')\nprint('Confusion Matrix:')\nprint(conf_matrix)\nprint('Classification Report:')\nprint(classification_rep)\n\n# Read the second dataset into df2\ndf2 = pd.read_csv('/kaggle/input/dataset/credit-debit dataset.csv')  \n\n# Feature columns for the second dataset\nfeatures_second = ['Total Credit Amount', 'Transaction Amount']\n\n# Additional feature columns for money sources and transaction accounts\nmoney_sources = 'Money Sources'\ntransaction_accounts = 'Transfer Accounts'\n\n# Target variable for the second dataset\ntarget_second = 'Fraud Indicator'\n\n# Drop rows with missing values\ndf2 = df2.dropna()\n\n# Convert categorical variables to dummy/indicator variables\ndf2 = pd.get_dummies(df2, columns=['Employment Status', 'Education Level', 'Marital Status'], drop_first=True)\n\n# Use MultiLabelBinarizer for one-hot encoding of accounts\nmlb = MultiLabelBinarizer()\n\n# Transform 'money_sources' and 'transaction_accounts' into binary features\nmoney_sources_encoded = pd.DataFrame(mlb.fit_transform(df2['Money Sources']), columns=mlb.classes_, index=df2.index)\ntransaction_accounts_encoded = pd.DataFrame(mlb.fit_transform(df2['Transfer Accounts']), columns=mlb.classes_, index=df2.index)\n\n# Concatenate the encoded features with the original DataFrame\ndf2 = pd.concat([df2, money_sources_encoded, transaction_accounts_encoded], axis=1)\n\n# Feature columns for the second dataset including the new binary account features\nfeatures_second += list(money_sources_encoded.columns) + list(transaction_accounts_encoded.columns)\n\n# Drop the original account columns\ndf2 = df2.drop(['Money Sources', 'Transfer Accounts'], axis=1)\n\n# Split the data into training and testing sets\nX_train_second, X_test_second, y_train_second, y_test_second = train_test_split(df2[features_second], df2[target_second], test_size=0.2, random_state=42)\n\n# Train a Random Forest classifier for the second dataset\nmodel_second = RandomForestClassifier(n_estimators=1000, random_state=42, verbose=1)\nmodel_second.fit(X_train_second, y_train_second)\n\n# Make predictions on the test set for the second model\npredictions_second = model_second.predict(X_test_second)\n\n# Evaluate the second model\naccuracy_second = accuracy_score(y_test_second, predictions_second)\nmse_second = mean_squared_error(y_test_second, predictions_second)\nrsquared_second = r2_score(y_test_second, predictions_second)\nconf_matrix_second = confusion_matrix(y_test_second, predictions_second)\nclassification_rep_second = classification_report(y_test_second, predictions_second)\n\n# Display results for the second model\nprint(f'Second Model Results:')\nprint(f'Accuracy: {accuracy_second:.2f}')\nprint(f'Mean Squared Error: {mse_second:.2f}')\nprint(f'R-squared: {rsquared_second:.2f}')\nprint('Confusion Matrix:')\nprint(conf_matrix_second)\nprint('Classification Report:')\nprint(classification_rep_second)\n\n# Combine outcomes of both models\ncombined_predictions = (y_pred + predictions_second) >= 1\n\n# Evaluate the combined model\ncombined_accuracy = accuracy_score(y_test, combined_predictions)\ncombined_mse = mean_squared_error(y_test, combined_predictions)\ncombined_rsquared = r2_score(y_test, combined_predictions)\ncombined_conf_matrix = confusion_matrix(y_test, combined_predictions)\ncombined_classification_rep = classification_report(y_test, combined_predictions)\n\n# Display results for the combined model\nprint(f'Combined Model Results:')\nprint(f'Accuracy: {combined_accuracy:.2f}')\nprint(f'Mean Squared Error: {combined_mse:.2f}')\nprint(f'R-squared: {combined_rsquared:.2f}')\nprint('Confusion Matrix:')\nprint(combined_conf_matrix)\nprint('Classification Report:')\nprint(combined_classification_rep)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T07:20:53.289584Z","iopub.execute_input":"2023-12-29T07:20:53.290031Z","iopub.status.idle":"2023-12-29T07:21:36.540200Z","shell.execute_reply.started":"2023-12-29T07:20:53.290004Z","shell.execute_reply":"2023-12-29T07:21:36.539236Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.1s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    4.4s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    9.9s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:   17.5s\n[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n","output_type":"stream"},{"name":"stdout","text":"First Model Results:\nAccuracy: 0.97\nMean Squared Error: 0.03\nR-squared: 0.87\nConfusion Matrix:\n[[2562    0]\n [ 118 1320]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98      2562\n           1       1.00      0.92      0.96      1438\n\n    accuracy                           0.97      4000\n   macro avg       0.98      0.96      0.97      4000\nweighted avg       0.97      0.97      0.97      4000\n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.8s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.3s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    7.6s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:   13.6s\n[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.9s\n","output_type":"stream"},{"name":"stdout","text":"Second Model Results:\nAccuracy: 0.86\nMean Squared Error: 0.14\nR-squared: 0.17\nConfusion Matrix:\n[[3010  141]\n [ 415  434]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92      3151\n           1       0.75      0.51      0.61       849\n\n    accuracy                           0.86      4000\n   macro avg       0.82      0.73      0.76      4000\nweighted avg       0.85      0.86      0.85      4000\n\nCombined Model Results:\nAccuracy: 0.89\nMean Squared Error: 0.11\nR-squared: 0.50\nConfusion Matrix:\n[[2208  354]\n [ 105 1333]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.86      0.91      2562\n           1       0.79      0.93      0.85      1438\n\n    accuracy                           0.89      4000\n   macro avg       0.87      0.89      0.88      4000\nweighted avg       0.90      0.89      0.89      4000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error, r2_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# Load the first dataset\ndata = pd.read_csv('/kaggle/input/dataset/TransactionDataset1.csv')\n\n# Drop unnecessary columns\ndrop_columns = ['user_id', 'name', 'addresses', 'email_address', 'transaction_id', 'transaction_date']\ndata = data.drop(drop_columns, axis=1)\n\n# Convert categorical variables to numerical using Label Encoding\nlabel_encoder = LabelEncoder()\nfor column in data.select_dtypes(include=['object']).columns:\n    data[column] = label_encoder.fit_transform(data[column])\n\n# Split the data into features (X) and target variable (y)\nX = data.drop('fraud_indicator', axis=1)\ny = data['fraud_indicator']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Choose a model (Feedforward Neural Network)\n# Perform GridSearchCV for hyperparameter tuning\nparam_grid = {\n    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n    'alpha': [0.0001, 0.001, 0.01],\n    'max_iter': [500, 1000, 1500]\n}\n\ngrid_search = GridSearchCV(MLPClassifier(random_state=42), param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\n# Print best parameters\nprint(\"Best parameters for the first model:\", grid_search.best_params_)\n\n# Apply best parameters to the first model\nmodel = grid_search.best_estimator_\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrsquared = r2_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\n# Display results for the first model\nprint(f'First Model Results:')\nprint(f'Accuracy: {accuracy:.2f}')\nprint(f'Mean Squared Error: {mse:.2f}')\nprint(f'R-squared: {rsquared:.2f}')\nprint('Confusion Matrix:')\nprint(conf_matrix)\nprint('Classification Report:')\nprint(classification_rep)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T07:21:49.970693Z","iopub.execute_input":"2023-12-29T07:21:49.971039Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\n# Read the second dataset into df2\ndf2 = pd.read_csv('/kaggle/input/dataset/credit-debit dataset.csv')  \n\n# Feature columns for the second dataset\nfeatures_second = ['Total Credit Amount', 'Transaction Amount']\n\n# Additional feature columns for money sources and transaction accounts\nmoney_sources = 'Money Sources'\ntransaction_accounts = 'Transfer Accounts'\n\n# Target variable for the second dataset\ntarget_second = 'Fraud Indicator'\n\n# Drop rows with missing values\ndf2 = df2.dropna()\n\n# Convert categorical variables to dummy/indicator variables\ndf2 = pd.get_dummies(df2, columns=['Employment Status', 'Education Level', 'Marital Status'], drop_first=True)\n\n# Use MultiLabelBinarizer for one-hot encoding of accounts\nmlb = MultiLabelBinarizer()\n\n# Transform 'money_sources' and 'transaction_accounts' into binary features\nmoney_sources_encoded = pd.DataFrame(mlb.fit_transform(df2['Money Sources']), columns=mlb.classes_, index=df2.index)\ntransaction_accounts_encoded = pd.DataFrame(mlb.fit_transform(df2['Transfer Accounts']), columns=mlb.classes_, index=df2.index)\n\n# Concatenate the encoded features with the original DataFrame\ndf2 = pd.concat([df2, money_sources_encoded, transaction_accounts_encoded], axis=1)\n\n# Feature columns for the second dataset including the new binary account features\nfeatures_second += list(money_sources_encoded.columns) + list(transaction_accounts_encoded.columns)\n\n# Drop the original account columns\ndf2 = df2.drop(['Money Sources', 'Transfer Accounts'], axis=1)\n\n# Split the data into training and testing sets\nX_train_second, X_test_second, y_train_second, y_test_second = train_test_split(df2[features_second], df2[target_second], test_size=0.2, random_state=42)\n\n# Perform GridSearchCV for hyperparameter tuning for the second model\nparam_grid_second = {\n    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n    'alpha': [0.0001, 0.001, 0.01],\n    'max_iter': [500, 1000, 1500]\n}\n\ngrid_search_second = GridSearchCV(MLPClassifier(random_state=42), param_grid_second, cv=5)\ngrid_search_second.fit(X_train_second, y_train_second)\n\n# Print best parameters\nprint(\"Best parameters for the second model:\", grid_search_second.best_params_)\n\n# Apply best parameters to the second model\nmodel_second = grid_search_second.best_estimator_\n\n# Train the second model\nmodel_second.fit(X_train_second, y_train_second)\n\n# Make predictions on the test set for the second model\npredictions_second = model_second.predict(X_test_second)\n\n# Evaluate the second model\naccuracy_second = accuracy_score(y_test_second, predictions_second)\nmse_second = mean_squared_error(y_test_second, predictions_second)\nrsquared_second = r2_score(y_test_second, predictions_second)\nconf_matrix_second = confusion_matrix(y_test_second, predictions_second)\nclassification_rep_second = classification_report(y_test_second, predictions_second)\n\n# Display results for the second model\nprint(f'Second Model Results:')\nprint(f'Accuracy: {accuracy_second:.2f}')\nprint(f'Mean Squared Error: {mse_second:.2f}')\nprint(f'R-squared: {rsquared_second:.2f}')\nprint('Confusion Matrix:')\nprint(conf_matrix_second)\nprint('Classification Report:')\nprint(classification_rep_second)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine outcomes of both models\ncombined_predictions = (y_pred + predictions_second) >= 1\n\n# Evaluate the combined model\ncombined_accuracy = accuracy_score(y_test, combined_predictions)\ncombined_mse = mean_squared_error(y_test, combined_predictions)\ncombined_rsquared = r2_score(y_test, combined_predictions)\ncombined_conf_matrix = confusion_matrix(y_test, combined_predictions)\ncombined_classification_rep = classification_report(y_test, combined_predictions)\n\n# Display results for the combined model\nprint(f'Combined Model Results:')\nprint(f'Accuracy: {combined_accuracy:.2f}')\nprint(f'Mean Squared Error: {combined_mse:.2f}')\nprint(f'R-squared: {combined_rsquared:.2f}')\nprint('Confusion Matrix:')\nprint(combined_conf_matrix)\nprint('Classification Report:')\nprint(combined_classification_rep)\n","metadata":{},"execution_count":null,"outputs":[]}]}