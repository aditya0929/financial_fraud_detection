{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install faker \n!pip install pydbgen","metadata":{"execution":{"iopub.status.busy":"2023-12-30T20:24:09.490983Z","iopub.execute_input":"2023-12-30T20:24:09.491440Z","iopub.status.idle":"2023-12-30T20:24:38.004515Z","shell.execute_reply.started":"2023-12-30T20:24:09.491404Z","shell.execute_reply":"2023-12-30T20:24:38.003424Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: faker in /opt/conda/lib/python3.10/site-packages (22.0.0)\nRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.10/site-packages (from faker) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\nCollecting pydbgen\n  Downloading pydbgen-1.0.5-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: Faker in /opt/conda/lib/python3.10/site-packages (from pydbgen) (22.0.0)\nRequirement already satisfied: Pandas in /opt/conda/lib/python3.10/site-packages (from pydbgen) (2.0.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pydbgen) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.10/site-packages (from Faker->pydbgen) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from Pandas->pydbgen) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from Pandas->pydbgen) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from Pandas->pydbgen) (1.24.3)\nInstalling collected packages: pydbgen\nSuccessfully installed pydbgen-1.0.5\n","output_type":"stream"}]},{"cell_type":"code","source":"from faker import Faker\nimport pandas as pd\nimport random\n\n# Initialize Faker\nfake = Faker()\n\n# Generate synthetic data for a dataset with duplicates in phone numbers\nnum_records = 20000\n\n# Generate unique phone numbers first\nphone_numbers = [fake.phone_number() for _ in range(num_records)]\n\n# Introduce duplicates for some phone numbers\nduplicates_ratio = 0.3\nnum_duplicates = int(num_records * duplicates_ratio)\nduplicated_phone_numbers = random.sample(phone_numbers, num_duplicates)\nphone_numbers = phone_numbers + duplicated_phone_numbers\n\n# Shuffle the entire dataset\ndata = list(zip(\n    [fake.name() for _ in range(num_records)],\n    phone_numbers,\n    [fake.email() for _ in range(num_records)],\n    [fake.credit_card_number(card_type='mastercard') for _ in range(num_records)]\n))\nrandom.shuffle(data)\n\n# Unpack the shuffled data into separate lists\nnames, phone_numbers, emails, bank_account_numbers = zip(*data)\n\n# Create a Pandas DataFrame from the synthetic data\ndf = pd.DataFrame({\n    'Name': names,\n    'Phone Number': phone_numbers,\n    'Email': emails,\n    'Bank Account Number': bank_account_numbers,\n})\n\n# Print the lengths of the arrays\nfor key, value in df.items():\n    print(f'Length of {key}: {len(value)}')\n# Save the dataset to a CSV file\ndf.to_csv('synthetic_bank_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T20:44:39.569484Z","iopub.execute_input":"2023-12-30T20:44:39.569872Z","iopub.status.idle":"2023-12-30T20:44:39.662091Z","shell.execute_reply.started":"2023-12-30T20:44:39.569844Z","shell.execute_reply":"2023-12-30T20:44:39.660924Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Length of Name: 100\nLength of Phone Number: 100\nLength of Email: 100\nLength of Bank Account Number: 100\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}