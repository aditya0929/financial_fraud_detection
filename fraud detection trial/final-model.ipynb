{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7282058,"sourceType":"datasetVersion","datasetId":4222368}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-16T12:50:46.650621Z","iopub.execute_input":"2024-01-16T12:50:46.651185Z","iopub.status.idle":"2024-01-16T12:50:47.042280Z","shell.execute_reply.started":"2024-01-16T12:50:46.651153Z","shell.execute_reply":"2024-01-16T12:50:47.041449Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/credit-debit dataset.csv\n/kaggle/input/dataset/TransactionDataset1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer\nfrom sklearn.impute import SimpleImputer\nimport joblib\nimport os\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T12:55:53.520133Z","iopub.execute_input":"2024-01-16T12:55:53.520596Z","iopub.status.idle":"2024-01-16T12:55:53.527616Z","shell.execute_reply.started":"2024-01-16T12:55:53.520563Z","shell.execute_reply":"2024-01-16T12:55:53.526550Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess the data\ndef preprocess_data(data):\n    # Select relevant features\n    selected_features = ['age', 'kyc_status', 'days_since_kyc_incomplete', 'transaction_amount',\n                         'home_branch', 'transaction_location', 'transaction_method',\n                         'transaction_category', 'transaction_merchant', 'transaction_time',\n                         'average_expenditure', 'comparison_with_avg_expenditure',\n                         'transaction_count_7_days', 'suspicion_indicator',\n                         'Total Credit Amount', 'Transaction Amount']\n\n    # Drop irrelevant columns\n    data = data[selected_features + ['fraud_indicator']]\n\n    # Handle missing values\n    data = data.dropna()\n\n    # Label encoding for categorical variables\n    label_encoder = LabelEncoder()\n    data[data.select_dtypes(include=['object']).columns] = data.select_dtypes(include=['object']).apply(lambda col: label_encoder.fit_transform(col.astype(str)))\n\n    return data, label_encoder\n\n# Load datasets\ndata1_path = '/kaggle/input/dataset/TransactionDataset1.csv'\ndata2_path = '/kaggle/input/dataset/credit-debit dataset.csv'\n\n# Check if files exist before attempting to read\nif not os.path.isfile(data1_path):\n    print(f\"Error: File not found - {data1_path}\")\nelse:\n    data1 = pd.read_csv(data1_path)\n\nif not os.path.isfile(data2_path):\n    print(f\"Error: File not found - {data2_path}\")\nelse:\n    data2 = pd.read_csv(data2_path)\n\n# Preprocess data\npreprocessed_data, label_encoder = preprocess_data(pd.concat([data1, data2], axis=1))\n\n# Separate features and target variable\nX = preprocessed_data.drop('fraud_indicator', axis=1)\ny = preprocessed_data['fraud_indicator']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use SimpleImputer to handle missing values by filling NaNs with the mean\nimputer = SimpleImputer(strategy='mean')\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_imputed)\nX_test_scaled = scaler.transform(X_test_imputed)\n\n# Choose a model (Random Forest)\nmodel = RandomForestClassifier(n_estimators=2000, random_state=42, verbose=1)\n\n# Train the model\nmodel.fit(X_train_scaled, y_train)\n\n# Display the features\nprint(\"Features of the RandomForest model:\")\nfor feature_name in X.columns:\n    print(feature_name)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test_scaled)\n\n# Display confusion matrix and classification report\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_rep)\n\n# Save the model, scaler, and label encoder\nmodel_filename = '/kaggle/working/random_forest_fraud.pkl'\njoblib.dump({\n    'label_encoder': label_encoder,\n    'scaler': scaler,\n    'model': model,\n    'features': X.columns.tolist()  # Save the features used for training\n}, model_filename)\n\nprint(f'Model, scaler, and label encoder saved as {model_filename}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T12:56:15.257745Z","iopub.execute_input":"2024-01-16T12:56:15.258190Z","iopub.status.idle":"2024-01-16T12:57:22.377461Z","shell.execute_reply.started":"2024-01-16T12:56:15.258156Z","shell.execute_reply":"2024-01-16T12:57:22.375878Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.4s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.5s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:   25.7s\n[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   40.0s\n[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   57.6s\n","output_type":"stream"},{"name":"stdout","text":"Features of the RandomForest model:\nage\nkyc_status\ndays_since_kyc_incomplete\ntransaction_amount\nhome_branch\ntransaction_location\ntransaction_method\ntransaction_category\ntransaction_merchant\ntransaction_time\naverage_expenditure\ncomparison_with_avg_expenditure\ntransaction_count_7_days\nsuspicion_indicator\nTotal Credit Amount\nTransaction Amount\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.8s\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n[[2562    0]\n [ 118 1320]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98      2562\n           1       1.00      0.92      0.96      1438\n\n    accuracy                           0.97      4000\n   macro avg       0.98      0.96      0.97      4000\nweighted avg       0.97      0.97      0.97      4000\n\nModel, scaler, and label encoder saved as /kaggle/working/random_forest_fraud.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}